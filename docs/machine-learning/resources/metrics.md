---
title: ML.NET 메트릭
description: ML.NET 모델의 성능을 평가하기 위해 사용한 메트릭 이해
ms.date: 04/29/2019
author: natke
ms.openlocfilehash: 362f2f382d050ff9ae246af2dffe3e15d22452eb
ms.sourcegitcommit: 944ddc52b7f2632f30c668815f92b378efd38eea
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 11/03/2019
ms.locfileid: "73460738"
---
# <a name="model-evaluation-metrics-in-mlnet"></a><span data-ttu-id="7446a-103">ML.NET에서 모델 평가 메트릭</span><span class="sxs-lookup"><span data-stu-id="7446a-103">Model evaluation metrics in ML.NET</span></span>

## <a name="metrics-for-binary-classification"></a><span data-ttu-id="7446a-104">이진 분류용 메트릭</span><span class="sxs-lookup"><span data-stu-id="7446a-104">Metrics for Binary Classification</span></span>

| <span data-ttu-id="7446a-105">메트릭</span><span class="sxs-lookup"><span data-stu-id="7446a-105">Metrics</span></span>   |      <span data-ttu-id="7446a-106">설명</span><span class="sxs-lookup"><span data-stu-id="7446a-106">Description</span></span>      |  <span data-ttu-id="7446a-107">살펴볼 항목</span><span class="sxs-lookup"><span data-stu-id="7446a-107">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="7446a-108">**정확도(Accuracy)**</span><span class="sxs-lookup"><span data-stu-id="7446a-108">**Accuracy**</span></span> |  <span data-ttu-id="7446a-109">[정확도](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification)는 테스트 데이터 세트 사용 시 올바른 예측의 비율입니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-109">[Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) is the proportion of correct predictions with a test data set.</span></span> <span data-ttu-id="7446a-110">총 입력 샘플 수 대비 올바른 예측 수의 비율입니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-110">It is the ratio of number of correct predictions to the total number of input samples.</span></span> <span data-ttu-id="7446a-111">각 클래스에 유사한 수의 샘플이 속해 있는 경우에만 제대로 작동합니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-111">It works well only if there are similar number of samples belonging to each class.</span></span>| <span data-ttu-id="7446a-112">**1.00에 가까울 수록 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="7446a-112">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="7446a-113">하지만 정확하게 1.00은 문제(일반적으로 레이블/대상 누출, 오버피팅 또는 학습 데이터 테스트)를 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-113">But exactly 1.00 indicates an issue (commonly: label/target leakage, over-fitting, or testing with training data).</span></span> <span data-ttu-id="7446a-114">테스트 데이터의 균형이 맞지 않은 경우(대부분 인스턴스가 클래스 중 하나에 속해 있는 경우) 데이터 세트가 아주 작거나 점수가 0.00 또는 1.00에 근접하면 정확도는 실제로 분류자의 유효성을 포착하지 못하므로 추가 메트릭을 확인해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-114">When the test data is unbalanced (where most of the instances belong to one of the classes), the dataset is very small, or scores approach 0.00 or 1.00, then accuracy doesn’t really capture the effectiveness of a classifier and you need to check additional metrics.</span></span> |
| <span data-ttu-id="7446a-115">**AUC**</span><span class="sxs-lookup"><span data-stu-id="7446a-115">**AUC**</span></span> |    <span data-ttu-id="7446a-116">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) 또는 *곡선 아래의 영역*: 참 긍정 비율과 거짓 긍정 비율을 스윕하여 생성된 곡선 아래의 영역을 측정하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-116">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) or *Area under the curve*: This is measuring the area under the curve created by sweeping the true positive rate vs. the false positive rate.</span></span>  |   <span data-ttu-id="7446a-117">**1.00에 가까울 수록 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="7446a-117">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="7446a-118">0\.50보다 큰 모델은 수용 가능하며 AUC가 0.50 또는 미만인 모델은 가치가 없습니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-118">It should be greater than 0.50 for a model to be acceptable; a model with AUC of 0.50 or less is worthless.</span></span> |
| <span data-ttu-id="7446a-119">**AUCPR**</span><span class="sxs-lookup"><span data-stu-id="7446a-119">**AUCPR**</span></span> | <span data-ttu-id="7446a-120">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) 또는 *정밀도-리콜 곡선의 아래의 영역*: 클래스의 균형이 매우 좋지 않을 때(상당히 기울어진 데이터 세트) 예측 성공에 대한 의미 있는 측정값입니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-120">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) or *Area under the curve of a Precision-Recall curve*: Useful measure of success of prediction when the classes are very imbalanced (highly skewed datasets).</span></span> |  <span data-ttu-id="7446a-121">**1.00에 가까울 수록 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="7446a-121">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="7446a-122">1\.00에 가까운 고득점은 분류자가 정확한 결과(높은 정밀도)를 반환할 뿐만 아니라 대다수가 모두 긍정 결과(높은 재현율)를 반환하고 있음을 보여줍니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-122">High scores close to 1.00 show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).</span></span> |
| <span data-ttu-id="7446a-123">**F1-점수(F1-score)**</span><span class="sxs-lookup"><span data-stu-id="7446a-123">**F1-score**</span></span> | <span data-ttu-id="7446a-124">*balanced F-score 또는 F-measure*라고도 하는 [F1 점수](https://en.wikipedia.org/wiki/F1_score)는</span><span class="sxs-lookup"><span data-stu-id="7446a-124">[F1 score](https://en.wikipedia.org/wiki/F1_score) also known as *balanced F-score or F-measure*.</span></span> <span data-ttu-id="7446a-125">정밀도와 재현율의 조화 평균입니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-125">It's the harmonic mean of the precision and recall.</span></span> <span data-ttu-id="7446a-126">F1 점수는 정밀도(Precision)와 재현율(Recall) 간 균형을 찾으려고 할 때 유용합니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-126">F1 Score is helpful when you want to seek a balance between Precision and Recall.</span></span>| <span data-ttu-id="7446a-127">**1.00에 가까울 수록 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="7446a-127">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="7446a-128">F1 점수에서 가장 높은 값은 1.00이고 가장 낮은 점수는 0.00으로,</span><span class="sxs-lookup"><span data-stu-id="7446a-128">An F1 score reaches its best value at 1.00 and worst score at 0.00.</span></span> <span data-ttu-id="7446a-129">분류자의 정밀도를 알려줍니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-129">It tells you how precise your classifier is.</span></span> |

<span data-ttu-id="7446a-130">이진 분류 메트릭에 대한 자세한 내용은 다음 메트릭 문서를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="7446a-130">For further details on binary classification metrics read the following articles:</span></span>

- [<span data-ttu-id="7446a-131">정확도, 정밀도, 재현율 또는 F1?</span><span class="sxs-lookup"><span data-stu-id="7446a-131">Accuracy, Precision, Recall or F1?</span></span>](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)
- [<span data-ttu-id="7446a-132">이진 분류 메트릭 클래스</span><span class="sxs-lookup"><span data-stu-id="7446a-132">Binary Classification Metrics class</span></span>](xref:Microsoft.ML.Data.BinaryClassificationMetrics)
- [<span data-ttu-id="7446a-133">정밀도-재현율과 ROC 곡선 간의 관계</span><span class="sxs-lookup"><span data-stu-id="7446a-133">The Relationship Between Precision-Recall and ROC Curves</span></span>](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)

## <a name="metrics-for-multi-class-classification"></a><span data-ttu-id="7446a-134">다중 클래스 분류용 메트릭</span><span class="sxs-lookup"><span data-stu-id="7446a-134">Metrics for Multi-class Classification</span></span>

| <span data-ttu-id="7446a-135">메트릭</span><span class="sxs-lookup"><span data-stu-id="7446a-135">Metrics</span></span>   |      <span data-ttu-id="7446a-136">설명</span><span class="sxs-lookup"><span data-stu-id="7446a-136">Description</span></span>      |  <span data-ttu-id="7446a-137">살펴볼 항목</span><span class="sxs-lookup"><span data-stu-id="7446a-137">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="7446a-138">**Micro-정확도**</span><span class="sxs-lookup"><span data-stu-id="7446a-138">**Micro-Accuracy**</span></span> |  <span data-ttu-id="7446a-139">[Micro 평균 정확도](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy)는 모든 클래스의 기여도를 집계하여 평균 메트릭을 컴퓨팅합니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-139">[Micro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) aggregates the contributions of all classes to compute the average metric.</span></span> <span data-ttu-id="7446a-140">정확하게 예측된 인스턴스의 일부분으로서,</span><span class="sxs-lookup"><span data-stu-id="7446a-140">It is the fraction of instances predicted correctly.</span></span> <span data-ttu-id="7446a-141">Micro-평균은 클래스 멤버 자격을 고려하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-141">The micro-average does not take class membership into account.</span></span> <span data-ttu-id="7446a-142">기본적으로, 모든 샘플-클래스 쌍은 정확도 메트릭에 동일기하게 기여합니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-142">Basically, every sample-class pair contributes equally to the accuracy metric.</span></span> | <span data-ttu-id="7446a-143">**1.00에 가까울 수록 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="7446a-143">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="7446a-144">다중 클래스 분류 작업에서는 클래스 불균형이 있을 것으로 의심되는 경우(예:</span><span class="sxs-lookup"><span data-stu-id="7446a-144">In a multi-class classification task, micro-accuracy is preferable over macro-accuracy if you suspect there might be class imbalance (i.e</span></span> <span data-ttu-id="7446a-145">다른 클래스의 예보다 한 클래스의 예가 훨씬 많을 수 있음) Macro-정확도보다 Micro-정확도가 더 낫습니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-145">you may have many more examples of one class than of other classes).</span></span>|
| <span data-ttu-id="7446a-146">**Macro-정확도**</span><span class="sxs-lookup"><span data-stu-id="7446a-146">**Macro-Accuracy**</span></span> | <span data-ttu-id="7446a-147">[Macro-평균 정확도](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy)는 클래스 수준에서는 평균 정확도입니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-147">[Macro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) is the average accuracy at the class level.</span></span> <span data-ttu-id="7446a-148">각 클래스에 대한 정확도가 계산되고 Macro-정확도는 이러한 정확도의 평균입니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-148">The accuracy for each class is computed and the macro-accuracy is the average of these accuracies.</span></span> <span data-ttu-id="7446a-149">기본적으로, 모든 클래스는 정확도 메트릭에 동일하게 기여합니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-149">Basically, every class contributes equally to the accuracy metric.</span></span> <span data-ttu-id="7446a-150">소수 클래스는 큰 클래스와 같은 가중치를 부여받습니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-150">Minority classes are given equal weight as the larger classes.</span></span> <span data-ttu-id="7446a-151">Macro-평균 메트릭은 데이터 세트에 포함된 클래스의 인스턴스 수가 얼마나 많던지 상관없이 각 클래스에 동일한 가중치를 부여합니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-151">The macro-average metric gives the same weight to each class, no matter how many instances from that class the dataset contains.</span></span> |  <span data-ttu-id="7446a-152">**1.00에 가까울 수록 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="7446a-152">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="7446a-153">각 클래스에 대해 독립적으로 메트릭을 계산한 다음, 평균을 냅니다(따라서 모든 클래스를 동일하게 처리).</span><span class="sxs-lookup"><span data-stu-id="7446a-153">It computes the metric independently for each class and then takes the average (hence treating all classes equally)</span></span> |
| <span data-ttu-id="7446a-154">**로그 손실**</span><span class="sxs-lookup"><span data-stu-id="7446a-154">**Log-loss**</span></span>| <span data-ttu-id="7446a-155">[로그 손실](http://wiki.fast.ai/index.php/Log_Loss)은 분류 모델의 성과를 측정합니다. 여기에서 예측 입력은 0.00과 1.00 사이의 확률 값입니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-155">[Logarithmic loss](http://wiki.fast.ai/index.php/Log_Loss) measures the performance of a classification model where the prediction input is a probability value between 0.00 and 1.00.</span></span> <span data-ttu-id="7446a-156">로그 손실은 예측된 확률이 실제 레이블에서 나뉘면서 증가합니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-156">Log-loss increases as the predicted probability diverges from the actual label.</span></span> | <span data-ttu-id="7446a-157">**0.00에 가까울 수록 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="7446a-157">**The closer to 0.00, the better**.</span></span> <span data-ttu-id="7446a-158">완벽한 모델은 로그 손실이 0.00이 됩니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-158">A perfect model would have a log-loss of 0.00.</span></span> <span data-ttu-id="7446a-159">기계 학습 모델의 목표는 이 값을 최소화하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-159">The goal of our machine learning models is to minimize this value.</span></span>|
| <span data-ttu-id="7446a-160">**로그 손실 감소(Log-Loss Reduction)**</span><span class="sxs-lookup"><span data-stu-id="7446a-160">**Log-Loss Reduction**</span></span> | <span data-ttu-id="7446a-161">[로그 손실 감소](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction)는 임의 예측에 대한 분류자의 이점으로 해석할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-161">[Logarithmic loss reduction](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) can be interpreted as the advantage of the classifier over a random prediction.</span></span>| <span data-ttu-id="7446a-162">**-inf ~1.00의 범위입니다. 여기서 1.00은 완벽한 예측이고 0.00은 평균 예측을 나타냅니다**.</span><span class="sxs-lookup"><span data-stu-id="7446a-162">**Ranges from -inf and 1.00, where 1.00 is perfect predictions and 0.00 indicates mean predictions**.</span></span> <span data-ttu-id="7446a-163">예를 들어 값이 0.20이라면 “정확한 예측의 확률이 임의 추측보다 20% 나음”으로 해석할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-163">For example, if the value equals 0.20, it can be interpreted as "the probability of a correct prediction is 20% better than random guessing"</span></span>|

<span data-ttu-id="7446a-164">Micro-정확도는 일반적으로 ML 예측의 비즈니스 요구 사항과 더 잘 맞습니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-164">Micro-accuracy is generally better aligned with the business needs of ML predictions.</span></span> <span data-ttu-id="7446a-165">다중 클래스 분류 작업의 품질을 선택하기 위해 단일 메트릭을 선택하려는 경우 일반적으로 micro-정확도여야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-165">If you want to select a single metric for choosing the quality of a multiclass classification task, it should usually be micro-accuracy.</span></span>

<span data-ttu-id="7446a-166">예를 들어, 지원 티켓 분류 작업: (들어오는 티켓을 지원 팀에 매핑)</span><span class="sxs-lookup"><span data-stu-id="7446a-166">Example, for a support ticket classification task: (maps incoming tickets to support teams)</span></span>

- <span data-ttu-id="7446a-167">Micro-정확도 - 들어오는 티켓이 올바른 팀으로 분류되는 빈도</span><span class="sxs-lookup"><span data-stu-id="7446a-167">Micro-accuracy -- how often does an incoming ticket get classified to the right team?</span></span>
- <span data-ttu-id="7446a-168">Macro-정확도 - 평균 팀의 경우 들어오는 티켓이 해당 팀에 정확한 빈도</span><span class="sxs-lookup"><span data-stu-id="7446a-168">Macro-accuracy -- for an average team, how often is an incoming ticket correct for their team?</span></span>

<span data-ttu-id="7446a-169">Macro-정확도는 이 예에서 작은 팀에 가중치를 초과 부과합니다. 여기서 작은 팀은 매년 10개의 티켓을 받고, 큰 팀은 매년 1만 개의 티켓을 받습니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-169">Macro-accuracy overweights small teams in this example; a small team which gets only 10 tickets per year counts as much as a large team with 10k tickets per year.</span></span> <span data-ttu-id="7446a-170">이 경우에 Micro-정확도는 “내 티켓 라우팅 프로세스를 자동화하여 회사가 절감할 수 있는 시간/비용 정도”라는 비즈니스 요구 사항과 상관 관계가 더 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-170">Micro-accuracy in this case correlates better with the business need of, "how much time/money can the company save by automating my ticket routing process".</span></span>

<span data-ttu-id="7446a-171">다중 클래스 분류 메트릭에 대한 더 자세한 내용은 다음 문서를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="7446a-171">For further details on multi-class classification metrics read the following articles:</span></span>

- [<span data-ttu-id="7446a-172">정밀도, 재현율 및 F 점수의 Micro-및 Macro-평균</span><span class="sxs-lookup"><span data-stu-id="7446a-172">Micro- and Macro-average of Precision, Recall and F-Score</span></span>](https://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html)
- [<span data-ttu-id="7446a-173">불균형 데이터 세트를 사용한 다중 클래스 분류</span><span class="sxs-lookup"><span data-stu-id="7446a-173">Multiclass Classification with Imbalanced Dataset</span></span>](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a)

## <a name="metrics-for-regression"></a><span data-ttu-id="7446a-174">회귀용 메트릭</span><span class="sxs-lookup"><span data-stu-id="7446a-174">Metrics for Regression</span></span>

| <span data-ttu-id="7446a-175">메트릭</span><span class="sxs-lookup"><span data-stu-id="7446a-175">Metrics</span></span>   |      <span data-ttu-id="7446a-176">설명</span><span class="sxs-lookup"><span data-stu-id="7446a-176">Description</span></span>      |  <span data-ttu-id="7446a-177">살펴볼 항목</span><span class="sxs-lookup"><span data-stu-id="7446a-177">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="7446a-178">**R-제곱(R-Squared)**</span><span class="sxs-lookup"><span data-stu-id="7446a-178">**R-Squared**</span></span> |  <span data-ttu-id="7446a-179">[R-제곱(R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination) 또는 *결정 계수*는 -inf와 1.00 사이의 값으로 모델의 예측력을 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-179">[R-squared (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), or *Coefficient of determination* represents the predictive power of the model as a value between -inf and 1.00.</span></span> <span data-ttu-id="7446a-180">1.00은 완벽한 적합도를 의미하며, 적합도는 임의적으로 나쁠 수 있으므로 점수는 음수가 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-180">1.00 means there is a perfect fit, and the fit can be arbitrarily poor so the scores can be negative.</span></span> <span data-ttu-id="7446a-181">점수 0.00은 모델이 레이블의 예상 값을 추측하고 있음을 의미합니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-181">A score of 0.00 means the model is guessing the expected value for the label.</span></span> <span data-ttu-id="7446a-182">R2는 실제 테스트 데이터 값이 예측 값에 근접한 정도를 측정합니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-182">R2 measures how close the actual test data values are to the predicted values.</span></span> | <span data-ttu-id="7446a-183">**1.00에 가까울 수록 품질이 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="7446a-183">**The closer to 1.00, the better quality**.</span></span> <span data-ttu-id="7446a-184">단, 낮은 R-제곱 값(예: 0.50)이 사용자의 시나리오에 완전히 정상이거나 충분히 좋을 수 있으며 높은 R-제곱 값이 항상 좋고 의심스러운 것이 아닌 경우가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-184">However, sometimes low R-squared values (such as 0.50) can be entirely normal or good enough for your scenario and high R-squared values are not always good and be suspicious.</span></span> |
| <span data-ttu-id="7446a-185">**절대-손실(Absolute-loss)**</span><span class="sxs-lookup"><span data-stu-id="7446a-185">**Absolute-loss**</span></span> |  <span data-ttu-id="7446a-186">[절대 손실](https://en.wikipedia.org/wiki/Mean_absolute_error) 또는 *평균 절대 오차(MAE)* 는 예측이 실제 결과에 근접한 정도를 측정합니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-186">[Absolute-loss](https://en.wikipedia.org/wiki/Mean_absolute_error) or *Mean absolute error (MAE)* measures how close the predictions are to the actual outcomes.</span></span> <span data-ttu-id="7446a-187">모든 모델 오차의 평균이며, 여기서 모델 오차는 예측된 레이블 값과 올바른 레이블 값 사이의 절대 거리입니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-187">It is the average of all the model errors, where model error is the absolute distance between the predicted label value and the correct label value.</span></span> <span data-ttu-id="7446a-188">이 예측 오차는 테스트 데이터 세트의 각 레코드에 대해 계산됩니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-188">This prediction error is calculated for each record of the test data set.</span></span> <span data-ttu-id="7446a-189">마지막으로, 평균 값은 모든 기록된 절대 오차에 대해 계산됩니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-189">Finally, the mean value is calculated for all recorded absolute errors.</span></span>| <span data-ttu-id="7446a-190">**0.00에 가까울 수록 품질이 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="7446a-190">**The closer to 0.00, the better quality.**</span></span> <span data-ttu-id="7446a-191">절대 평균 오차는 측정 중인 데이터와 동일한 척도를 사용합니다(특정 범위로 정규화되지 않은).</span><span class="sxs-lookup"><span data-stu-id="7446a-191">Note that the mean absolute error uses the same scale as the data being measured (is not normalized to specific range).</span></span> <span data-ttu-id="7446a-192">절대-손실, 제곱근-손실 및 RMS 손실은 레이블 값 분산이 유사한 데이터 세트 또는 동일한 데이터 세트의 모델 간에 비교하기 위해서만 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-192">Absolute-loss, Squared-loss, and RMS-loss can only be used to make comparisons between models for the same dataset or dataset with a similar label value distribution.</span></span> |
| <span data-ttu-id="7446a-193">**제곱-손실(Squared-loss)**</span><span class="sxs-lookup"><span data-stu-id="7446a-193">**Squared-loss**</span></span> |  <span data-ttu-id="7446a-194">[제곱-손실](https://en.wikipedia.org/wiki/Mean_squared_error) 또는 *평균 제곱 오차(MSE)* (또는 *평균 제곱근 편차(MSD))* 는 회귀선이 테스트 데이터 값 세트와 근접한 정도를 알려줍니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-194">[Squared-loss](https://en.wikipedia.org/wiki/Mean_squared_error) or *Mean Squared Error (MSE)*, also called *Mean Squared Deviation (MSD)*, tells you how close a regression line is to a set of test data values.</span></span> <span data-ttu-id="7446a-195">점에서 회귀선까지의 거리(이러한 거리가 오차 E임)를 측정한 후 제곱하여 계산합니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-195">It does this by taking the distances from the points to the regression line (these distances are the errors E) and squaring them.</span></span> <span data-ttu-id="7446a-196">제곱은 큰 차이에 더 많은 가중치를 부여합니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-196">The squaring gives more weight to larger differences.</span></span> | <span data-ttu-id="7446a-197">항상 음수가 아니며 **값이 0.00에 가까울 수록 더 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="7446a-197">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="7446a-198">데이터에 따라 평균 제곱근 오차의 아주 작은 값을 가져오는 것이 불가능할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-198">Depending on your data, it may be impossible to get a very small value for the mean squared error.</span></span>|
| <span data-ttu-id="7446a-199">**RMS-손실(RMS-loss)**</span><span class="sxs-lookup"><span data-stu-id="7446a-199">**RMS-loss**</span></span> |  <span data-ttu-id="7446a-200">[RMS-손실](https://en.wikipedia.org/wiki/Root-mean-square_deviation) 또는 *평균 제곱 오차(Root Mean Square Error, RMSE)* (또는 *평균 제곱 편차(Root Mean Square Deviation, RMSD*))는 모델에서 예측한 값과 모델링하려는 환경에서 실제 관찰된 값 사이의 차이를 측정합니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-200">[RMS-loss](https://en.wikipedia.org/wiki/Root-mean-square_deviation) or *Root Mean Squared Error (RMSE)* (also called *Root Mean Square Deviation, RMSD*), measures the difference between values predicted by a model and the values actually observed from the environment that is being modeled.</span></span> <span data-ttu-id="7446a-201">RMS-손실은 제곱 손실의 제곱근이며 큰 차이에 더 많은 가중치를 부여함으로써 절대-손실과 유사하게, 레이블과 단위가 동일합니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-201">RMS-loss is the square root of Squared-loss and has the same units as the label, similar to the absolute-loss though giving more weight to larger differences.</span></span> <span data-ttu-id="7446a-202">평균 제곱 오차는 실험적 결과를 검증하기 위해 일반적으로 기후학, 예측 및 회귀 분석에 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-202">Root mean square error is commonly used in climatology, forecasting, and regression analysis to verify experimental results.</span></span> | <span data-ttu-id="7446a-203">항상 음수가 아니며 **값이 0.00에 가까울 수록 더 좋습니다**.</span><span class="sxs-lookup"><span data-stu-id="7446a-203">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="7446a-204">RMSD는 척도 종속적이므로, 데이터 세트 간이 아니라 특정 데이터 세트에 대해 다양한 모델의 예측 오차를 비교하기 위한 정확도 측도입니다.</span><span class="sxs-lookup"><span data-stu-id="7446a-204">RMSD is a measure of accuracy, to compare forecasting errors of different models for a particular dataset and not between datasets, as it is scale-dependent.</span></span>|

<span data-ttu-id="7446a-205">회귀 메트릭에 대한 자세한 내용은 다음 문서를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="7446a-205">For further details on regression metrics, read the following articles:</span></span>

- [<span data-ttu-id="7446a-206">회귀 분석: R-제곱을 해석하고 적합성(Goodness-of-Fit)을 평가하려면 어떻게 하나요?</span><span class="sxs-lookup"><span data-stu-id="7446a-206">Regression Analysis: How Do I Interpret R-squared and Assess the Goodness-of-Fit?</span></span>](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)
- [<span data-ttu-id="7446a-207">회귀 분석에서 R-제곱을 해석하는 방법</span><span class="sxs-lookup"><span data-stu-id="7446a-207">How To Interpret R-squared in Regression Analysis</span></span>](https://statisticsbyjim.com/regression/interpret-r-squared-regression)
- [<span data-ttu-id="7446a-208">R-제곱 정의</span><span class="sxs-lookup"><span data-stu-id="7446a-208">R-Squared Definition</span></span>](https://www.investopedia.com/terms/r/r-squared.asp)
- [<span data-ttu-id="7446a-209">평균 제곱 오차 정의</span><span class="sxs-lookup"><span data-stu-id="7446a-209">Mean Squared Error Definition</span></span>](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/)
- [<span data-ttu-id="7446a-210">평균 제곱 오차 및 평균 제곱근 오차의 정의</span><span class="sxs-lookup"><span data-stu-id="7446a-210">What are Mean Squared Error and Root Mean Squared Error?</span></span>](https://www.vernier.com/til/1014/)
